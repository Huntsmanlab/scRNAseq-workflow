---
title: '`r params$ids` DE analysis using edgeR'
author: "aslÄ±"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output: 
  html_document:
    code_folding: hide

params:
  ids: 'DH21-DH21_control' 
---


```{r include = FALSE}

# source some files / packages 
library(here)
source(here('pipeline', 'sourceFiles', 'utilities.R'))

```

```{r include = FALSE}
# load the sces
ids <- strsplit(params$ids, "-")[[1]] # split by "-" SO ID must NOT CONTAIN "-"
dh_organoid_ids <- list(ids[[1]], ids[[2]])

# make a list of the sces 
# we are loading the clustered sces, since we will be using the clusters as replicates  
sces <- lapply(dh_organoid_ids, function(dh_organoid_ids) readRDS(here('..', 'DH_organoid', 'data', 'clustered', 'sce', dh_organoid_ids, 'sce_clus.rds')))

# rename the elements in the list based on the ids
names(sces) <- paste(dh_organoid_ids)

# find the common genes in our sces 
universal <- Reduce(intersect, list(rownames(sces[[1]]), rownames(sces[[2]])))

# only keep the common genes in all sces 
sces <- lapply(sces, function(sce) sce <- sce[universal, ])

# make the pseudo counts / sum all the counts in one sample. as if we had 2 bulk samples, not scRNA 
counts_list <- lapply(sces, function(sce) as.data.frame(rowSums(counts(sce))))
counts <- cbind(counts_list[[1]], counts_list[[2]]) # combine them into one counts matrix 
names(counts)[1] <- "control" # rename the columns in the counts matrix 
names(counts)[2] <- "experimental"

# make the DGE object 
dgeObject <- DGEList(counts = counts, genes = rownames(counts), group = factor(c(1, 2)))

# filter the lowly expressed genes - have at least in 0.5 cpm in at least 2 samples 
keep <- rowSums(cpm(dgeObject) > 0.5) >= 2 
dgeObject <- dgeObject[keep, ]

# make sure sces also have the same genes as the dgeObject after filtering 
geneSet <- intersect(dgeObject$genes[, 1], universal)

# only keep the common genes 
sces <- lapply(sces, function(sce) sce <- sce[geneSet, ])

```


```{r include = FALSE}
# in this part, we will try to find some control transcripts that are not DE between the two samples we have. we will use their counts to estimate dispersion. our assumption is that a few DE 
# genes won't change the dispersion greatly. the idea is that the chosen housekeeping gene is uniformly expressed with low variance under both control and experimental conditions.

# load the data that has the potential candidates 
candidates <- read.xlsx(file = here('..', 'data', 'misc', 'candidate_stable_genes.xlsx'), sheetName = 'human development')

# we are only interested in genes with stability index more than 70 percent; genes less than 1965 is lower than 70 percent. 
candidates <- candidates[1:1965, ] 

# find the genes in both: candidates and our geneset. remember that geneset includes the genes found in both sces after removing the low counts. 
common <- intersect(candidates[, 1], geneSet)

# sum across features, this allows us to have only one count for each gene
summed_counts_list <- lapply(sces, function(sce) as.data.frame(rowSums(as.data.frame(counts(sce)))))

# turn the row names into a column so that we can keep the gene names after filtering 
summed_counts_list <- lapply(summed_counts_list, function(df) rownames_to_column(df))

# get the indices of candidate genes in our samples 
indices <- match(common, summed_counts_list[[1]][, 1])

# now do the subsetting and keep the counts for candidate genes only
summed_counts_list[[1]] <- summed_counts_list[[1]][indices, c(1, 2)]
summed_counts_list[[2]] <- summed_counts_list[[2]][indices, c(1, 2)]

################################################################################################################################################

# extract the number of nonzero cells for each feature in each sample and make a list. in other works find how many cells express the gene of interest 
cell_num_list <- lapply(sces, function(sce) nexprs(sce, byrow = TRUE))

# now subset these counts to only keep the genes we are interested in  
cell_num_list <- lapply(cell_num_list, function(cell_num) as.data.frame(cell_num)[indices, ])

# we have the nnumber of cells that express the gene. now lets convert that to percentage, with 2 decimal places. 
# note that dim(sce)[[2]] gives us the total number of cells in that sce 
sces1_percent <- round((cell_num_list[[1]] / dim(sces[[1]])[[2]]) * 100, 2)
sces2_percent <- round((cell_num_list[[2]] / dim(sces[[2]])[[2]]) * 100, 2)

################################################################################################################################################

# we need to count the number of zeroes in a row. to do that, first convert our sparse matrix into a data frame: 
counts_df <- lapply(sces, function(sce) as.data.frame(as.matrix(counts(sce))))

# convert all zeroes into NAs, this will allow us to use some built in functions for NA.
counts_df[[1]][counts_df[[1]] == 0] <- NA
counts_df[[2]][counts_df[[2]] == 0] <- NA

# SUMS
# now count the number of non NAs in each row. 
sample1_non_zero <- rowSums(!is.na(counts_df[[1]]))
sample2_non_zero <- rowSums(!is.na(counts_df[[2]]))

# subset to the interesting genes 
sample1_non_zero <- as.data.frame(sample1_non_zero)[indices, ]
sample2_non_zero <- as.data.frame(sample2_non_zero)[indices, ]

#MEANS 
sample1_non_zero_mean <- rowMeans(counts_df[[1]], na.rm = TRUE)
sample2_non_zero_mean <- rowMeans(counts_df[[2]], na.rm = TRUE)

# subset to the interesting genes 
sample1_non_zero_mean <- as.data.frame(sample1_non_zero_mean)[indices, ]
sample2_non_zero_mean <- as.data.frame(sample2_non_zero_mean)[indices, ]

################################################################################################################################################

# now we will work with the clustering data. basically we need to figure out in how many clusters our gene is expressed in the integrated data set. 

# load the integrated clustering data. the data here was prepared by combining the samples together and running a clustering algorithm where we treat 
# the integrated sample as one. 
integrated_samples <- readRDS(file = here('..', 'data', 'clustered', 'combined', paste(dh_organoid_ids[[1]], dh_organoid_ids[[2]], sep = '-'), 'integrated_seurat_object'))

# we want to know in which clusters a gene is expressed. For that, we need to find the cluster numbers where the cells that express our gene are grouped in.
# so we will go from gene to cell to cluster. 

# each ROW is a cell. 
cluster_info <- as.data.frame(integrated_samples$cluster)

# every COLUMN is a cell. this df has the counts for each cell for each gene. we will replace the counts info with the cluster info for each respective cell. 
counts_info <- as.data.frame(integrated_samples@assays$RNA@counts)

# for replacing, repeat the cluster numbers as many times as the total number of genes
n <- dim(counts_info)[[1]] #replicate as many times as the number genes 
cluster_info <- cbind(cluster_info, replicate(n, cluster_info[, 1])) 

# now we transpose our df to put it in the same format as the counts matrix, remember that we want genes in the rows. 
genes_in_clusters <- data.frame(t(cluster_info[-1]))
colnames(genes_in_clusters) <- rownames(cluster_info) # rownames are cells 
rownames(genes_in_clusters) <- rownames(counts_info) # colnames are genes 

# remember that some genes were not expressed in some cells, those are the NAs. let's add that to our data frame: 
# first, cbind the two counts data. 
overall_counts <- cbind(counts_df[[1]], counts_df[[2]])

# put the genes in alphabetical order in both data frames and convert rownames to a column
overall_counts <- overall_counts[order(rownames(overall_counts)), ]
genes_in_clusters <- genes_in_clusters[order(rownames(genes_in_clusters)), ]

# turn row names into a column 
overall_counts <- rownames_to_column(overall_counts)
genes_in_clusters <- rownames_to_column(genes_in_clusters)

# make the column names the same between the two data frames otherwise R complains 
colnames(overall_counts) <- colnames(genes_in_clusters)

# do a merge, but only keep the genes present in both data frames 
joined <- merge(genes_in_clusters, overall_counts, by = 'rowname', all.y = TRUE)

# clean up the merge 
joined <- joined[, 1:dim(genes_in_clusters)[[2]]]

# replace everything that is not NA with the values in the same position in the joined data set 
overall_counts[!is.na(overall_counts)] <- joined[!is.na(overall_counts)]

# find the intersect of gene names we defined earlier and the genes we have in the table 
common <- intersect(summed_counts_list[[1]][, 1], overall_counts$rowname)
indices <- match(common, overall_counts$rowname)
overall_counts <- overall_counts[indices, ] # subset the main gene table with the genes we are interested in 

# find the number of unique elements, -1 because it counts the column names as a unique element as well and we dont want that 
unique_clusters <- apply(overall_counts, 1, function(x) length(unique(na.omit(x)))) - 1

# now convert the number aboe to percentage 
cluster_percentage <- round(((as.numeric(as.character(unique_clusters))) / max(as.numeric(integrated_samples$cluster))) * 100, 2)

################################################################################################################################################

# COMBINE ALL IN A DATA FRAME: 

# before binding, make sure they are in the type we want:

sces1_percent <- as.numeric(as.character(sces1_percent))
sces2_percent <- as.numeric(as.character(sces2_percent))
sample1_non_zero <- as.numeric(as.character(sample1_non_zero))
sample2_non_zero <- as.numeric(as.character(sample2_non_zero))
unique_clusters <- as.numeric(as.character(unique_clusters))
cluster_percentage <- as.numeric(as.character(cluster_percentage))

stability_index_df <- data.frame(
  
                            cbind(
                              
                            summed_counts_list[[1]][, 1], # gene names
                            cell_num_list[[1]], # number of nonzero cells that express this gene in sample 1 
                            cell_num_list[[2]],
                            sces1_percent, # percentage of cells where the gene is expressed in sample 1
                            sces2_percent, 
                            sample1_non_zero, # sum of COUNTS for this gene specifically in sample 1. 
                            sample2_non_zero, 
                            sample1_non_zero_mean, # mean of counts for a gene across all cells 
                            sample2_non_zero_mean,
                            unique_clusters, # number of unique clusters the gene is expressed in 
                            cluster_percentage # percentage of total number of clusters the gene is expressed in 
                            ), 
                            
                            stringsAsFactors = FALSE)


# now we add the sd for each row. this will help understand how similar a gene is across two samples
sd_nonzero_means <- round(apply(stability_index_df[, 8:9], 1, sd), 2)

# add the standard devs to the data table 
stability_index_df <- cbind(stability_index_df, s_devs)

# get the indices that fit to our criteria 
keep <- which(stability_index_df$sces1_percent > 60 & 
                stability_index_df$sces2_percent > 60 & 
                sample1_non_zero > 50 & 
                sample2_non_zero > 50 & 
                sd_nonzero_means < 1) 

# subset 
stability_filtered <- stability_index_df[keep, ]

# save this data frame to be loaded later
# saveRDS()

# name of the housekeeping genes
housekeeping_names <- stability_filtered[, 1]

# find teh indices of these genes in the original counts matrix 
housekeeping_indices <- match(housekeeping_names, rownames(dgeObject$counts))
```

Histograms of candidate housekeeping genes 
Here, we show the mean count of genes per cell
```{r echo = FALSE, message = FALSE,}
# show the distribution of the mean counts for our genes 

show_means <- function(data) {
  
  mean_counts_hist <- ggplot(data, aes(x = data[, 1])) +  # number of genes is given under the column named "detected" 
    geom_histogram(fill = "gold2", color = "black", bins = 25) + 
    ylab("Number of genes") + 
    xlab('mean number of detected counts per cell') + 
    scale_x_continuous(limits = c(0.7, 10), breaks = scales::pretty_breaks(n = 10)) + 
    theme_amunzur 
  
  return(mean_counts_hist) } 
control_plot <- show_means(as.data.frame(sample1_non_zero_mean)) + ggtitle('control sample')
experimental_plot <- show_means(as.data.frame(sample2_non_zero_mean)) + ggtitle('experimental sample')

gridExtra::grid.arrange(control_plot, experimental_plot, nrow = 1)

```

```{r include = FALSE}

group <- factor(c(1, 2))
# designMatrix <- model.matrix(~group)

designMatrix <- matrix(data = c(0, 1, 0, 1), ncol = 2, nrow = 2, dimnames = list(c('sample1', 'sample2'), c('control', 'treatment')))

designMatrix <- matrix(1, 2, 1)

# designMatrix <- model.matrix(~0+group)


BvsA <- makeContrasts(control - experimental - group1, levels=design)

# normalize using edgeR's method 
dgeObject <- calcNormFactors(dgeObject)

# estimate dispersion from the house keeping genes 
dgeObject1 <- dgeObject # create a copy of the data object with only one treatment group
dgeObject1$samples$group <- 1 # assume it is all one big treatment 

# Then estimate the common dispersion from the housekeeping genes and all the libraries as one group
temporary <- estimateDisp(dgeObject1[housekeeping_indices, ], design = designMatrix, trend="none", tagwise=FALSE, )

# insert the dispersion estimate into our original object 
dgeObject$common.dispersion <- temporary$common.dispersion

```


```{r include = FALSE}
# now that we have the dispersion estimates and the linear model, we will work on DE using quasi-likelihood (QL) F-test. 
# this is better than a regular linear model because it accounts for the uncertainity in the dispersion estimates and gives us more flexibility. 

# first fit a negative binomial model to the data 
fit <- glmQLFit(dgeObject, designMatrix, robust = TRUE)

# the baseline is group one. here, we compare group 2 to group 1. if we had 3 groups and said coef = 3, this would mean comparing group 3 to group1. 
# in other words, here we test the null hypothesis that coef1 - coef2 is equal to zero. 
qlf <- glmQLFTest(fit)

# you can use this piece of code to see the top genes: 
# topTags(qlf) 

# only get the genes with fold changes more than 0.5 
tr <- glmTreat(fit, coef = 2, lfc = 2)

# to find genes DE in all the groups: 
# qlf <- glmQLFTest(fit, coef = 2:3)

# DE GENE EXPRESSION ABOVE A THRESHOLD
# Note that the fold-change threshold here is not the minimum value of the fold-change. Genes will need to exceed this threshold
# before being declared statistically significant. we will use the same negative binomial fit but just for this time, add a threshold. 
qlf_threshold <- glmTreat(fit, coef = 2, lfc = 0.5)
# topTags(qlf_threshold)

# Map gene names to entrez ids for goana and kegga. we have to convert from ensembl ids to entrez ids. 
geneIDs <- ensembldb::select(EnsDb.Hsapiens.v75, keys = rownames(qlf), keytype = "SYMBOL", columns = c("SYMBOL","ENTREZID"))

# sometimes we get duplicates, remove those 
geneIDs <- geneIDs[!duplicated(geneIDs$SYMBOL), ]

# lets make sure we have the same genes in both 
idx <- is.na(geneIDs$ENTREZID)
idx_keep <- which(idx == FALSE)
qlf_modified <- qlf[idx_keep, ]

# drop the NAs, these are the genes we couldn't find an entrez id for 
geneIDs <- na.omit(geneIDs)

# do some gene enrichment 
go <- goana(qlf_modified, geneid = geneIDs$ENTREZID, species="Hs") # entrez gene ids are in mapping 

# visualize goana results 
# topGO(go, sort="up") 

keg <- kegga(qlf_modified, geneid = geneIDs$ENTREZID, species="Hs")

# visualize kegga results
# topKEGG(keg, sort="up")

```

```{r include = FALSE}
# NEGATIVE CONTROL - here we mix shuffle the cells and then divide them into the same separate clusters. since they are randomly distributed, this analysis shouldnt return any DE genes. 

# add the id besides the name of the clusters in the sces 
sces_neg <- sces

sces_neg[[1]]$cluster <- paste(dh_organoid_ids[[1]], sces_neg[[1]]$cluster, sep = '_')
sces_neg[[2]]$cluster <- paste(dh_organoid_ids[[2]], sces_neg[[2]]$cluster, sep = '_')

# combine sces 
combined_sces <- combine_sces(sces_neg[[1]], sces_neg[[2]])

# shuffle the clusters 
combined_sces$cluster <- sample(combined_sces$cluster)

# make the combos, this will help us sum the cells in each cluster 
combo <- with(colData(combined_sces), paste(cluster))

# make the pseudo counts 
pseudoCounts <- sumCountsAcrossCells(counts(combined_sces), combo) # sum across cluster. this means add all the expression values for each gene for all cells in the cluster 
    
colnames(pseudoCounts) <- as.numeric(colnames(pseudoCounts)) # convert the column names to integers
    
pseudoCounts <- as.data.frame(pseudoCounts) # now convert it from double to data frame. 
    
# colnames(pseudoCounts) <- paste(colnames(pseudoCounts), paste(dh_organoid_ids[[i]]), sep = '_') # add the id of the sample next to the cluster number

# make the dge object
# now we have pseudo bulk counts for our sces. we will use these pseudo counts to make the dge list objects. do lapply to make dgelist objects of all our pseudo counts 
dgeObject_neg <- DGEList(counts = pseudoCounts, genes = rownames(pseudoCountsList))

# filter the lowly expressed genes 
keep <- filterByExpr(dgeObject_neg)
dgeObject_neg <- dgeObject_neg[keep, ]

# make the group, do this by repeating the number of treatments as many times as the number of clusters, which represent the number of replicates. 
# now we make a vector showing how many times each sample should be repeated.
i <- 1
clustersRepeated <- list()
idsRepeated <- list()
max_sce <- length(sces) 
  
while (i <= length(sces)) {
  
  # repeat the sample index as many times as the number of clusters. this is equivalent to repeating the treatment condition as many times as the replicates. 
  clustersRepeated <- append(clustersRepeated, unlist(rep(i, max(as.numeric(colData(sces[[i]])$cluster)))))  
   
  id <- dh_organoid_ids[[i]]
  idsRepeated <- append(idsRepeated, rep(id, max(as.numeric(colData(sces[[i]])$cluster)))) # same thing, repeat the id as many times as the cluster number. we will append them together. 
  
  i <- i + 1
    
} 

# lets repeat the cluster numbers as many times as the ids repeated 
group <- mapply(paste, clustersRepeated, idsRepeated, SIMPLIFY = FALSE, sep = '_')

# now our group is a list, but we need to turn it into a vector to be able to use it in EdgeR
group <- c(unlist(group))

# normalize using edgeR's method 
dgeObject_neg <- calcNormFactors(dgeObject_neg)

# make a data frame explaning the set up. we are making the treatment column of our data frame 
sample <- paste('sample', 1:length(group), sep = '_')
treatment <- c(unlist(idsRepeated))

setup <- as.data.frame(sample, treatment)
setup <- cbind(sample, treatment)

rownames(setup) <- setup[, 1]

# make the model, we pick one with the intercept. 
designMatrix <- model.matrix(~treatment)

# estimate the dispersion of genes to prepare for fitting the linear model, note that this may take some time
dgeObject_neg <- estimateDisp(dgeObject_neg, designMatrix)

# do some filtering on the dge object to remove genes with low counts. we base the filtering on cpm (counts per million)
# For the current analysis, we keep genes that have CPM values above 0.5 in at least two libraries
keep <- rowSums(edgeR::cpm(dgeObject) > 0.5) >= 2
table(keep)

# The DGEList object is subsetted to retain only the non-filtered genes. we add keep.lib.sizes=FALSE because lib sizes are recalculated after drop some genes. 
dgeObject_neg <- dgeObject_neg[keep, , keep.lib.sizes=FALSE]

# now that we have the dispersion estimates and the linear model, we will work on DE using quasi-likelihood (QL) F-test. 
# this is better than a regular linear model because it accounts for the uncertainity in the dispersion estimates and gives us more flexibility. 

# first fit a negative binomial model to the data 
fit <- glmQLFit(dgeObject_neg, designMatrix, robust = TRUE)

# the baseline is group one. here, we compare group 2 to group 1. if we had 3 groups and said coef = 3, this would mean comparing group 3 to group1. 
# in other words, here we test the null hypothesis that coef1 - coef2 is equal to zero. 
qlf <- glmQLFTest(fit, coef = 2)

# fit the neg binomial model and run the QL tests 
fit_neg_control <- glmQLFit(dgeObject_neg, designMatrix, robust = TRUE)
qlf_neg_control <- glmQLFTest(fit_neg_control, coef = 2)
neg_control_plot <- plotMD(qlf_neg_control)

```

### Diagnostic Plots 
These plots are intended to give an idea about the model and whether it is a good fit to represent the data we are interested in analyzing. 

Plot samples (replicates, in this case clusters) on a two-dimensional scatterplot so that distances on the plot approximate the expression differences between the samples.  
Clusters shown far apart mean they that are different in terms of gene expression. Cluster shown together are more similar in terms of gene expression.  
```{r echo = FALSE, message = FALSE, fig.width = 8, fig.height = 6}
MDSplot <- plotMDS(dgeObject)
MDSplot
```

#### Plot biological coefficient of variation against gene abundance, in log2 counts per million.  
Biological coefficient of variation is the true variation between genes, and it corresponds to the dispersion parameter of the negative binomial model. To learn more about dispersion, variation and how they relate to one another, read more about the negative binomial model and its implementation in scRNA sequencing data.  
Look for these to make sure your the model is a good fit:  
**1.** High dispersion (variance) for low counts is expected. Dispersion is expected to decrease smoothly as the abundance increases.  
**2.** For humans, common dispersion (the red line) should be around 0.3 - 0.4, meaning replicates can differ by 30% or more. If the common dispersion is more,  
YOU SHOULD NOT BE USING THIS SCRIPT. High dispersion values will influence the differential expression analysis.  

**This plot will give you a measure of the variation between the samples. **
```{r, echo = FALSE, message = FALSE, fig.height = 5, fig.width = 7}
# plot biological coefficient of variation against gene abundance, in ln counts per million 
BCVplot <- plotBCV(dgeObject)
BCVplot
```

#### Plot the genewise quasi-likelihood dispersion against the gene abundance (in log2 counts per million).
In this script, we squeeze the dispersion values from raw counts towards the trended dispersion. (This just means we transform the data in certain ways to make the model fit.)
The plots gives an idea about how much the data was squeezed. The expected is too see squeezed dispersion values (shown in red) closer to the trended (blue) line
```{r,echo = FALSE, message = FALSE, fig.height = 7, fig.width = 7}
# Plot the genewise quasi-likelihood dispersion against the gene abundance (in ln counts per million).
dispersion <- plotQLDisp(fit)
dispersion
```


#### Plot the differentially expressed genes  
The blue lines indicate 1-fold up or down. The number of genes that are significantly up or down regulated are shown in the table, according to the plot.  
```{r, echo = FALSE, message = FALSE, fig.height = 10, fig.width = 7}
# plot the differentially expressed genes 
MDplot <- plotMD(qlf, main = paste('differentially expressed genes in', dh_organoid_ids[[2]], 'compared to', dh_organoid_ids[[1]]), ylab = 'log2 fold change')
MDplot
abline(h=c(-1,1), col="blue")
```


Take a closer look at the genes visualized above: 
```{r, echo = FALSE, message = FALSE}
summary <- summary(decideTests(qlf))

summary %>% 
    knitr::kable(caption = paste('comparing', dh_organoid_ids[[2]], 'to', dh_organoid_ids[[1]])) %>% 
    kable_styling(full_width = F)
```


Now we narrow down the DE genes a little bit to visualize genes with a reasonably large expression changes. This is helpful to list the biologically more meaningful genes.  
We restrict the fold change to 0.5.  
```{r echo = FALSE, message = FALSE, fig.height = 10, fig.width = 7}

MDplot2 <- plotMD(tr, main = paste('differentially expressed genes in', dh_organoid_ids[[2]], 'compared to', dh_organoid_ids[[1]]), ylab = 'log2 fold change')
MDplot2

```

#### Upregulated genes 
Now we take a closer look at the **upregulated** genes. To look for interesting genes, we do the following filtering:  
We don't show genes with log fold change (LogFC) less than 0.5. 
We also eliminate genes with p values more than 0.05.  
We resticted this table to first 50 genes. 
  
To help interpret, we use the follwing ranking system: 
Genes are ranked separately for log fold change (high to low) and p values (low to high). We then add these ranks together to get **summed_ranks.**  
Genes with smaller summed_ranks have high fold changes and low p values.  
```{r include = FALSE}

# here we do some manipulation to show the upregulated genes in a meaningful way 
upregulated_genes_table <- make_upreg_table(qlf)%>%
  mutate_at(vars(logFC), funs(round(., 3)))

DT::datatable(upregulated_genes_table,
  extensions = 'Buttons',
  options = list(dom = 'Bfrtip',
                 buttons = list("copy", "excel", "csv", "pdf")))

# # save the table to be loaded later 
write.csv(upregulated_genes_table, file = here('..', 'data', 'dge', 'edgeR_up', paste(params$ids)))

```

#### Downregulated genes 
Filtering and ranking systems is the same as upregulated genes, as explained above. Genes with the highest fold changes and lowest p values have lower summed_ranks.
  
```{r echo = FALSE, message = FALSE}

# here we do some manipulation to show the upregulated genes in a meaningful way 
downregulated_genes_table <- make_downreg_table(qlf) %>% 
  mutate_at(vars(logFC), funs(round(., 3)))

DT::datatable(downregulated_genes_table, 
  extensions = 'Buttons', 
  options = list(dom = 'Bfrtip', 
                 buttons = list("copy", "excel", "csv", "pdf")))

# save the table to be loaded later 
write.csv(downregulated_genes_table, file = here('..', 'data', 'dge', 'edgeR_down', paste(params$ids)))

```


This table tells us how many genes up or down regulated in the analysis with the given log fold change:  
```{r echo = FALSE, message = FALSE}

summary <- summary(decideTests(tr))

summary %>% 
    knitr::kable(caption = paste('comparing', dh_organoid_ids[[2]], 'to', dh_organoid_ids[[1]])) %>% 
    kable_styling(full_width = F)

```

### Gene enrichment  
#### GO Pathway analysis  
Understanding the table:  
**Ont:**  
Note that GO shows three complementary biological concepts including Biological Process (BP), Molecular Function (MF) and Cellular Component (CC).  
You can find these in the 'Ont' column.  
**N:**  
number of genes in the GO term  
**Up:**  
number of up-regulated differentially expressed genes.  
**Down:**
number of down-regulated differentially expressed genes.
**P.Up**  
p-value for the representation of GO pathway in up-regulated genes  
**P.Down**  
p-value for the representation of GO pathway in down-regulated genes  
The above is also true for the KEGG table below. 

```{r echo = FALSE, message = FALSE}
# here we show the results of the go pathways 
gotable <- topGO(go, sort="up")

# do some cleaning up
DT::datatable(gotable, 
  extensions = 'Buttons', 
  options = list(dom = 'Bfrtip', 
                 buttons = list("copy", "excel", "csv", "pdf")))
  
```

#### KEGG analysis 

```{r echo = FALSE, message = FALSE}
# here we show the results of the KEGG analysis 
keggtable <- topKEGG(keg, sort="up")

# do some cleaning up
DT::datatable(keggtable, 
  extensions = 'Buttons', 
  options = list(dom = 'Bfrtip', 
                 buttons = list("copy", "excel", "csv", "pdf")))

```

```{r include = FALSE}
# now we make a heatmap to visualize the DE genes 
# convert the read counts into log2-counts-per-million (logCPM) values
logCPM <- cpm(dgeObject, prior.count=2, log=TRUE)
rownames(logCPM) <- dgeObject$genes$Symbol 
colnames(logCPM) <- paste(dgeObject$samples$group, 1:2, sep="-")
```

Negative Control
This should return to no / few DE genes. 
```{r echo = FALSE, message = FALSE, fig.height = 5, fig.width = 7}
neg_control_plot
```

